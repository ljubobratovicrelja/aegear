{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import imp\n",
    "\n",
    "import maze.classifier\n",
    "imp.reload(maze.classifier)\n",
    "\n",
    "from maze.classifier import Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32\n",
    "PATH_TO_DATA = '../data/training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformations: resize to the same size, convert to tensor, and normalize pixel values\n",
    "transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomResizedCrop(128, scale=(0.75, 1.25)),\n",
    "        transforms.RandomRotation(degrees=(-180, 180)),  # Random rotation\n",
    "        transforms.CenterCrop((IMG_HEIGHT, IMG_WIDTH)),  # Pad the image if it is smaller than the desired size\n",
    "        transforms.ToTensor(),  # Convert PIL Image to Torch Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize to ImageNet mean and standard deviation\n",
    "])\n",
    "\n",
    "# Create a dataset from your image folder\n",
    "# This assumes that your image folder has two subfolders: 'fish' and 'background', each containing images of the corresponding class\n",
    "dataset = datasets.ImageFolder(PATH_TO_DATA, transform=transform)\n",
    "\n",
    "# Split your dataset into training and validation sets\n",
    "train_size = int(0.95 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoaders for the training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_destination\n",
      "add_module\n",
      "apply\n",
      "bfloat16\n",
      "buffers\n",
      "call_super_init\n",
      "children\n",
      "conv1\n",
      "conv2\n",
      "conv3\n",
      "conv4\n",
      "cpu\n",
      "cuda\n",
      "double\n",
      "dropout\n",
      "dump_patches\n",
      "eval\n",
      "extra_repr\n",
      "fc1\n",
      "fc2\n",
      "fc3\n",
      "float\n",
      "forward\n",
      "get_buffer\n",
      "get_extra_state\n",
      "get_parameter\n",
      "get_submodule\n",
      "half\n",
      "ipu\n",
      "load_state_dict\n",
      "modules\n",
      "named_buffers\n",
      "named_children\n",
      "named_modules\n",
      "named_parameters\n",
      "parameters\n",
      "register_backward_hook\n",
      "register_buffer\n",
      "register_forward_hook\n",
      "register_forward_pre_hook\n",
      "register_full_backward_hook\n",
      "register_full_backward_pre_hook\n",
      "register_load_state_dict_post_hook\n",
      "register_module\n",
      "register_parameter\n",
      "register_state_dict_pre_hook\n",
      "requires_grad_\n",
      "set_extra_state\n",
      "share_memory\n",
      "state_dict\n",
      "to\n",
      "to_empty\n",
      "train\n",
      "training\n",
      "type\n",
      "xpu\n",
      "zero_grad\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model = Classifier()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define your optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Define your scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=20)\n",
    "\n",
    "# number of epochs to train the model\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store losses for each epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "pbar = tqdm(range(num_epochs), desc=\"Training\")\n",
    "\n",
    "for epoch in pbar:\n",
    "    # Initialize variables to store the total loss in this epoch\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    model.train()  # Set the model to training mode\n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        # Move the training data to the GPU\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels.float().view_as(outputs))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add this batch's loss to the total loss for this epoch\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.float().view_as(outputs))\n",
    "\n",
    "            # Add this batch's loss to the total loss for this epoch\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Divide the total loss by the number of batches to get the average loss for this epoch\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Add the average losses for this epoch to the lists\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    pbar.set_description(f\"Epoch {epoch+1}/{num_epochs}: train loss: {train_loss:.4f}, val loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a grid of validation data using matplotlib\n",
    "images, labels = next(iter(val_loader))\n",
    "\n",
    "# shuffle images and labels\n",
    "idx = torch.randperm(images.shape[0])\n",
    "images = images[idx]\n",
    "images = images[idx]\n",
    "\n",
    "# take only 32 images\n",
    "images = images[:32].to(device)\n",
    "labels = labels[:32].to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "outputs = outputs.squeeze(1).detach().cpu().numpy()  # Convert tensor to numpy array\n",
    "fig, axes = plt.subplots(nrows=4, ncols=8, figsize=(16, 8))\n",
    "for idx, image in enumerate(images):\n",
    "    # renormalize the image to [0-1]\n",
    "    image = image / 2 + 0.5\n",
    "\n",
    "    ax = axes.flatten()[idx]\n",
    "    ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    ax.set_title(f\"Prob: {outputs[idx]:.2f}\")\n",
    "    ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the model to a file\n",
    "#torch.save(model, '../data/models/model_cnn4_v3.pth')\n",
    "torch.save(model.state_dict(), '../data/models/model_cnn4_v4.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FishMaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
