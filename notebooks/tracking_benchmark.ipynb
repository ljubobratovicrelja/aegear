{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7d2125",
   "metadata": {},
   "source": [
    "# Tracking Benchmark\n",
    "\n",
    "This notebook performs tracking evaluation on the previously tracked and manually supervised dataset in the Aegear project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import Rbf\n",
    "\n",
    "from aegear.tracker import FishTracker\n",
    "from aegear.video import VideoClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe79d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Device selection\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf72924",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../data/training\"\n",
    "video_dir = \"../data/video\"\n",
    "\n",
    "public_base_url = \"https://storage.googleapis.com/aegear-training-data\"\n",
    "\n",
    "annotations = {\n",
    "\n",
    "    \"4_per_23\": {\n",
    "        \"file\": \"tracking_4_per_23_clean.json\",\n",
    "        \"annotation_url\": f\"{public_base_url}/tracking/tracking_4_per_23_clean.json\",\n",
    "        \"video_url\": f\"{public_base_url}/video/4_per_23.MOV\"\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "os.makedirs(video_dir, exist_ok=True)\n",
    "\n",
    "test_set = []\n",
    "\n",
    "bar = tqdm(annotations.items(), desc=\"Downloading from GCS\")\n",
    "for key, ann in bar:\n",
    "    bar.set_postfix_str(key)\n",
    "\n",
    "    annotations_file = os.path.join(dataset_dir, ann[\"file\"])\n",
    "    video_file = os.path.join(video_dir, f\"{key}.MOV\")\n",
    "\n",
    "    if not os.path.exists(annotations_file):\n",
    "        print(f\"Downloading {ann['annotation_url']}\")\n",
    "        urlretrieve(ann[\"annotation_url\"], annotations_file)\n",
    "\n",
    "    if not os.path.exists(video_file):\n",
    "        print(f\"Downloading {ann['video_url']}\")\n",
    "        urlretrieve(ann[\"video_url\"], video_file)\n",
    "    \n",
    "    # Load the annnotations json\n",
    "    with open(annotations_file, \"r\") as f:\n",
    "        annotations = json.load(f)\n",
    "        test_set.append(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5abb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the test data.\n",
    "annotations = test_set[0]\n",
    "\n",
    "# Load video and tracking\n",
    "video = VideoClip(video_file)\n",
    "gt_tracking = {item[\"frame_id\"]: tuple(item[\"coordinates\"]) for item in annotations[\"tracking\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tracking = {}\n",
    "def model_track_register(frame_id, centroid, confidence):\n",
    "    pred_tracking[frame_id] = (centroid, confidence)\n",
    "def ui_update(frame_id):\n",
    "    pass  # No-op for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FishTracker\n",
    "heatmap_model_path = \"../models/model_efficient_unet_2025-05-19.pth\"\n",
    "siamese_model_path = \"../models/model_siamese_2025-05-19.pth\"\n",
    "\n",
    "tracker = FishTracker(\n",
    "    heatmap_model_path=heatmap_model_path,\n",
    "    siamese_model_path=siamese_model_path,\n",
    "    tracking_threshold=0.9,\n",
    "    detection_threshold=0.9,\n",
    "    tracking_max_skip=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class TqdmProgressReporter:\n",
    "    def __init__(self, start_frame, end_frame):\n",
    "        self.start_frame = start_frame\n",
    "        self.end_frame = end_frame\n",
    "        self.total = end_frame - start_frame\n",
    "        self.pbar = tqdm(total=self.total, desc=\"Tracking Progress\")\n",
    "        self.last_frame = start_frame\n",
    "\n",
    "    def update(self, current_frame):\n",
    "        # Advance the bar by the number of frames processed since last update\n",
    "        self.pbar.update(current_frame - self.last_frame)\n",
    "        self.last_frame = current_frame\n",
    "\n",
    "    def still_running(self):\n",
    "        # Always True for notebook use\n",
    "        return True\n",
    "\n",
    "    def close(self):\n",
    "        self.pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_reporter = TqdmProgressReporter(min(gt_tracking.keys()), max(gt_tracking.keys()))\n",
    "\n",
    "tracker.run_tracking(\n",
    "    video,\n",
    "    min(gt_tracking.keys()),\n",
    "    max(gt_tracking.keys()),\n",
    "    model_track_register,\n",
    "    progress_reporter=progress_reporter,\n",
    "    ui_update=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume gt_tracking and pred_tracking are dicts: frame_id -> (x, y)\n",
    "gt_frames = np.array(sorted(gt_tracking.keys()))\n",
    "gt_coords = np.array([gt_tracking[f] for f in gt_frames])\n",
    "\n",
    "pred_frames = np.array(sorted(pred_tracking.keys()))\n",
    "pred_coords = np.array([pred_tracking[f][0] for f in pred_frames])\n",
    "\n",
    "# Fit RBF interpolators\n",
    "rbf_gt_x = Rbf(gt_frames, gt_coords[:, 0], function='multiquadric', epsilon=0.5)\n",
    "rbf_gt_y = Rbf(gt_frames, gt_coords[:, 1], function='multiquadric', epsilon=0.5)\n",
    "\n",
    "rbf_pred_x = Rbf(pred_frames, pred_coords[:, 0], function='multiquadric', epsilon=0.5)\n",
    "rbf_pred_y = Rbf(pred_frames, pred_coords[:, 1], function='multiquadric', epsilon=0.5)\n",
    "\n",
    "# Evaluate on the union of all frame IDs\n",
    "all_frames = np.arange(min(gt_frames.min(), pred_frames.min()), max(gt_frames.max(), pred_frames.max())+1)\n",
    "gt_interp = np.stack([rbf_gt_x(all_frames), rbf_gt_y(all_frames)], axis=1)\n",
    "pred_interp = np.stack([rbf_pred_x(all_frames), rbf_pred_y(all_frames)], axis=1)\n",
    "\n",
    "# Compute per-frame error\n",
    "errors = np.linalg.norm(gt_interp - pred_interp, axis=1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(gt_interp[:,0], gt_interp[:,1], label='GT')\n",
    "plt.plot(pred_interp[:,0], pred_interp[:,1], label='Pred')\n",
    "plt.legend()\n",
    "plt.title(\"Interpolated Trajectories\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(all_frames, errors)\n",
    "plt.title(\"Per-frame Error\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Error (px)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcf22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.array(errors)\n",
    "print(f\"Mean error: {np.nanmean(errors):.2f} px\")\n",
    "print(f\"Median error: {np.nanmedian(errors):.2f} px\")\n",
    "print(f\"Frames within 3px: {(errors < 3).sum() / len(errors):.2%}\")\n",
    "print(f\"Frames within 5px: {(errors < 5).sum() / len(errors):.2%}\")\n",
    "print(f\"False hits (>20px): {len(errors[errors > 20])}: {(errors > 20).sum() / len(errors):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10  # Number of worst cases to show\n",
    "crop_size = 128\n",
    "\n",
    "# Find indices of the N largest errors\n",
    "worst_indices = np.argsort(errors)[-N:][::-1]\n",
    "worst_frames = all_frames[worst_indices]\n",
    "\n",
    "fig, axes = plt.subplots(N, 2, figsize=(6, 3*N))\n",
    "for i, frame_id in enumerate(worst_frames):\n",
    "    frame = video.get_frame(float(frame_id) / video.fps)\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    # GT crop\n",
    "    gt_xy = gt_interp[worst_indices[i]]\n",
    "    gt_x, gt_y = int(gt_xy[0]), int(gt_xy[1])\n",
    "    gt_crop = frame[\n",
    "        max(gt_y-crop_size//2,0):gt_y+crop_size//2,\n",
    "        max(gt_x-crop_size//2,0):gt_x+crop_size//2\n",
    "    ]\n",
    "\n",
    "    # Pred crop\n",
    "    pred_xy = pred_interp[worst_indices[i]]\n",
    "    pred_x, pred_y = int(pred_xy[0]), int(pred_xy[1])\n",
    "    pred_crop = frame[\n",
    "        max(pred_y-crop_size//2,0):pred_y+crop_size//2,\n",
    "        max(pred_x-crop_size//2,0):pred_x+crop_size//2\n",
    "    ]\n",
    "\n",
    "    # Plot\n",
    "    axes[i, 0].imshow(gt_crop, cmap='gray')\n",
    "    axes[i, 0].set_title(f\"GT Frame {frame_id}\")\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    axes[i, 1].imshow(pred_crop, cmap='gray')\n",
    "    axes[i, 1].set_title(f\"Pred Frame {frame_id}\\nError: {errors[worst_indices[i]]:.1f}px\")\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a8afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10  # Number of cases to show\n",
    "crop_size = 128\n",
    "\n",
    "# Find indices where error is between 5 and 10 pixels\n",
    "mid_error_mask = (errors > 5) & (errors <= 10)\n",
    "mid_error_indices = np.where(mid_error_mask)[0]\n",
    "\n",
    "# If there are more than N, take the N largest errors in this range\n",
    "if len(mid_error_indices) > N:\n",
    "    selected = mid_error_indices[np.argsort(errors[mid_error_indices])[-N:][::-1]]\n",
    "else:\n",
    "    selected = mid_error_indices\n",
    "\n",
    "selected_frames = all_frames[selected]\n",
    "\n",
    "fig, axes = plt.subplots(len(selected), 2, figsize=(6, 3*len(selected)))\n",
    "if len(selected) == 1:\n",
    "    axes = np.expand_dims(axes, axis=0)  # Ensure axes is 2D\n",
    "\n",
    "for i, frame_id in enumerate(selected_frames):\n",
    "    frame = video.get_frame(float(frame_id) / video.fps)\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    # GT and Pred coordinates\n",
    "    gt_xy = gt_interp[selected[i]]\n",
    "    pred_xy = pred_interp[selected[i]]\n",
    "    gt_x, gt_y = int(gt_xy[0]), int(gt_xy[1])\n",
    "    pred_x, pred_y = int(pred_xy[0]), int(pred_xy[1])\n",
    "\n",
    "    # GT crop (for reference, unchanged)\n",
    "    gt_crop = frame[\n",
    "        max(gt_y-crop_size//2,0):gt_y+crop_size//2,\n",
    "        max(gt_x-crop_size//2,0):gt_x+crop_size//2\n",
    "    ]\n",
    "\n",
    "    # Pred crop\n",
    "    pred_crop = frame[\n",
    "        max(pred_y-crop_size//2,0):pred_y+crop_size//2,\n",
    "        max(pred_x-crop_size//2,0):pred_x+crop_size//2\n",
    "    ]\n",
    "\n",
    "    # Calculate relative positions in the pred crop\n",
    "    rel_gt_x = (gt_x - (pred_x - crop_size//2))\n",
    "    rel_gt_y = (gt_y - (pred_y - crop_size//2))\n",
    "    rel_pred_x = crop_size // 2\n",
    "    rel_pred_y = crop_size // 2\n",
    "\n",
    "    # Plot GT crop\n",
    "    axes[i, 0].imshow(gt_crop, cmap='gray')\n",
    "    axes[i, 0].set_title(f\"GT Frame {frame_id}\")\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    # Plot Pred crop with centroids\n",
    "    axes[i, 1].imshow(pred_crop, cmap='gray')\n",
    "    axes[i, 1].scatter([rel_gt_x], [rel_gt_y], c='r', marker='o', label='GT', s=40)\n",
    "    axes[i, 1].scatter([rel_pred_x], [rel_pred_y], c='b', marker='x', label='Pred', s=40)\n",
    "    axes[i, 1].set_title(f\"Pred Frame {frame_id}\\nError: {errors[selected[i]]:.1f}px\")\n",
    "    axes[i, 1].axis('off')\n",
    "    axes[i, 1].legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
